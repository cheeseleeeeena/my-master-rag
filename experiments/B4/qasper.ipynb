{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vanilla SBERT\n",
    "### Recall improvement\n",
    "- add title for dense embeddings: 46.86% -> 50.75%\n",
    "    - increase correct question = 64\n",
    "    - relative boost 8.3%\n",
    "    - increase 3.89 pts\n",
    "\n",
    "### Answer performance boost\n",
    "- unified: 35.86 -> 36.69\n",
    "    - relative boost 2.3%\n",
    "    - increase 8.3 pts\n",
    "- unifiedlarge: 31.99 -> 32.05\n",
    "    - no obvious improvement\n",
    "- llama3: 36.22 -> 37.20\n",
    "    - relative boost 2.7%\n",
    "    - increase 9.8 pts\n",
    "\n",
    "multisection error = 因爲無法完整 retrieve 到 來自不同 section 的片段導致 low recall (multisection 題目佔 所有 error cases的比例)\n",
    "notitle sbert 的 multisection error 數量：138\n",
    "full title sbert 的 multisection error 數量：134\n",
    "兩者沒有重疊。\n",
    "\n",
    "如果可以解決multisection 的問題，答對的題數可預期增加130+題。預期 recall 可以提升2倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import argparse\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "import jsonlines\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set, Union\n",
    "import numpy as np\n",
    "\n",
    "import evaluator\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n",
      "1451\n",
      "1451\n"
     ]
    }
   ],
   "source": [
    "# load required test data files\n",
    "\n",
    "# gold data\n",
    "gold_path: Path = Path(\"qasper/test_gold.json\")\n",
    "\n",
    "gold_data = json.load(open(gold_path))\n",
    "gold_answers_and_evidence = evaluator.get_answers_and_evidence(\n",
    "    gold_data, True\n",
    ")\n",
    "\n",
    "## processed test data\n",
    "processed_papar_path: Path = Path(\"qasper/test_papers.json\")\n",
    "test_papers: Dict[str, Dict] = utils.load_json(processed_papar_path)\n",
    "processed_questions_path: Path = Path(\"qasper/test_questions.json\")\n",
    "test_questions: Dict[str, Dict] = utils.load_json(processed_questions_path)\n",
    "\n",
    "print(len(test_papers))\n",
    "print(len(gold_answers_and_evidence))\n",
    "print(len(test_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions: 1451\n",
      "Max number of answer references per question: 6\n",
      "Average number of answer references per question: 2.45\n"
     ]
    }
   ],
   "source": [
    "# Average number of answer references per question\n",
    "\n",
    "all_gold_sections: Dict[str, List[List[str]]] = {}\n",
    "for question_id, references in gold_answers_and_evidence.items():\n",
    "    paper_id: str = test_questions[question_id][\"from_paper\"]\n",
    "    all_gold_sections[question_id] = []\n",
    "    for reference in references:\n",
    "        gold_sections: List[str] = evaluator.get_sections(reference[\"evidence\"], test_papers, paper_id)\n",
    "        all_gold_sections[question_id].append(gold_sections)\n",
    "print(f\"Total questions: {len(all_gold_sections)}\")\n",
    "print(f\"Max number of answer references per question: {max([len(answers) for answers in all_gold_sections.values()])}\")\n",
    "print(f\"Average number of answer references per question: {np.mean([len(answers) for answers in all_gold_sections.values()]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions that require answer from multiple sections: 276\n",
      "Percentage: 19.02%\n"
     ]
    }
   ],
   "source": [
    "# Total questions that require answer from multiple sections\n",
    "\n",
    "all_section_occurences: Dict[str, List[int]] = {}\n",
    "for question_id, references in all_gold_sections.items():\n",
    "    all_section_occurences[question_id] = [len(sections) for sections in references]\n",
    "\n",
    "multisection_occurences: Dict[str, List[int]] = {}\n",
    "for qid, occurs in all_section_occurences.items():\n",
    "    # print(f\"Question `{qid}`: {np.mean(occurs):.2f}\")\n",
    "    for occur_count in occurs:\n",
    "        if occur_count > 1:\n",
    "            multisection_occurences[qid] = occurs\n",
    "            # total_multisection_questions += 1\n",
    "            break\n",
    "print(f\"Total questions that require answer from multiple sections: {len(multisection_occurences)}\")\n",
    "print(f\"Percentage: {len(multisection_occurences)/len(all_section_occurences)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question `cc8b4ed3985f9bfbe1b5d7761b31d9bd6a965444`: [3, 1, 2, 1, 1, 1]\n",
      "Question `f7662b11e87c1e051e13799413f3db459ac3e19c`: [2, 2, 1, 1, 1, 1]\n",
      "Question `b584739622d0c53830e60430b13fd3ae6ff43669`: [2, 2, 1, 2, 2]\n",
      "Question `3319d56556ae1597a86384057db0831e32774b90`: [1, 1, 1, 1, 2]\n",
      "Question `bc8526d4805e2554adb2e9c01736d3f3a3b19895`: [1, 2, 1, 1]\n",
      "Question `6e040e80f2da69d50386a90a38ed6d2fa4f77bbd`: [1, 1, 2, 1]\n",
      "Question `aebd1f0d728d0de5f76238844da044a44109f76f`: [1, 1, 1, 2]\n",
      "Question `cb4086ad022197da79f28dc609d0de90108c4543`: [3, 1, 1, 1]\n",
      "Question `fe52b093735bb456d7e699aa9a2b806d2b498ba0`: [2, 1, 2, 1]\n",
      "Question `8b4bd0a962241ea548752212ebac145e2ced7452`: [2, 1, 2, 3]\n",
      "Question `371433bd3fb5042bacec4dfad3cfff66147c14f0`: [2, 1, 1, 2]\n",
      "Question `c19e9fd2f1c969e023fb99b74e78eb1f3db8e162`: [2, 1, 2, 2]\n",
      "Question `887d7f3edf37ccc6bf2e755dae418b04d2309686`: [1, 1, 1, 2]\n",
      "Question `780c7993d446cd63907bb38992a60bbac9cb42b1`: [0, 0, 0, 2]\n",
      "Question `f54e19f7ecece1bb0ef3171403ae322ad572ff00`: [0, 2, 1]\n",
      "Question `6c50871294562e4886ede804574e6acfa8d1a5f9`: [2, 0, 4, 0]\n",
      "Question `c58ef13abe5fa91a761362ca962d7290312c74e4`: [1, 1, 1, 6]\n",
      "Question `a77d38427639d54461ae308f3045434f81e497d0`: [1, 2, 1, 1]\n",
      "Question `5ed02ae6c534cd49d405489990f0e4ba0330ff1b`: [2, 0, 2]\n",
      "Question `935873b97872820b7b6100d6a785fba286b94900`: [0, 2, 2, 1]\n",
      "Question `0fe49431db5ffaa24372919daf24d8f84117bfda`: [2, 1, 1, 1]\n",
      "Question `20632fc4d2b693b5aabfbbc99ee5c1e9fc485dea`: [1, 4, 1]\n",
      "Question `a57e266c936e438aeeab5e8d20d9edd1c15a32ee`: [2, 0, 0]\n",
      "Question `27356a99290fcc01e3e5660af3405d2a6c6f6e7c`: [2, 1, 1]\n",
      "Question `1ecbbb60dc44a701e9c57c22167dd412711bb0be`: [1, 2, 1, 1]\n",
      "Question `088d42ecb1e15515f6a97a0da2fed81b61d61a23`: [1, 1, 3, 1]\n",
      "Question `f1d61b44105e651925d02a51e6d7ea10ea28ebd8`: [2, 1, 1]\n",
      "Question `108f99fcaf620fab53077812e8901870896acf36`: [3, 0, 3, 2]\n",
      "Question `7125db8334a7efaf9f7753f2c2f0048a56e74c49`: [1, 4, 1]\n",
      "Question `ae2142ee9e093ce485025168f4bcb3da4602739d`: [1, 2, 1, 1]\n",
      "Question `ebe1084a06abdabefffc66f029eeb0b69f114fd9`: [2, 2, 2]\n",
      "Question `cfdd583d01abaca923f5c466bb20e1d4b8c749ff`: [2, 3, 3]\n",
      "Question `91e361e85c6d3884694f3c747d61bfcef171bab0`: [2, 1, 1]\n",
      "Question `6295951fda0cfa2eb4259d544b00bc7dade7c01e`: [3, 0, 1]\n",
      "Question `6df57a21ca875e63fb39adece6a9ace5bb2b2cfa`: [2, 1, 1]\n",
      "Question `31e6062ba45d8956791e1b86bad7efcb6d1b191a`: [1, 2, 1]\n",
      "Question `c0355afc7871bf2e12260592873ffdb5c0c4c919`: [2, 2, 1]\n",
      "Question `47d54a6dd50cab8dab64bfa1f9a1947a8190080c`: [2, 1, 1]\n",
      "Question `67cb001f8ca122ea859724804b41529fea5faeef`: [2, 1, 2]\n",
      "Question `5a473f86052cf7781dfe40943ddf99bc9fe8a4e4`: [2, 2, 2]\n",
      "Question `18fbfb1f88c5487f739aceffd23210a7d4057145`: [3, 3, 0]\n",
      "Question `5d3e87937ecebf0695bece08eccefb2f88ad4a0f`: [3, 3, 3]\n",
      "Question `9c1f70affc87024b4280f0876839309b8dddd579`: [1, 4, 1]\n",
      "Question `f8264609a44f059b74168995ffee150182a0c14f`: [1, 6, 1]\n",
      "Question `441be93e2830cc0fc65afad6959db92754c9f5a8`: [2, 1, 0]\n",
      "Question `ecaa10a2d9927fa6ab6a954488f12aa6b42ddc1a`: [1, 1, 2]\n",
      "Question `5d03a82a70f7b1ab9829891403ec31607828cbd5`: [2, 1, 1]\n",
      "Question `6cad6f074b0486210ffa4982c8d1632f5aa91d91`: [1, 2, 1]\n",
      "Question `d38b3e0896b105d171e69ce34c689e4a7e934522`: [1, 2, 1]\n",
      "Question `e2c8d7f3ef5913582503e50244ca7158d0a62c42`: [0, 1, 2]\n",
      "Question `74396ead9f88a9efc7626240ce128582ab69ef2b`: [1, 2, 1]\n",
      "Question `8a7a9d205014c42cb0e24a0f3f38de2176fe74c0`: [2, 1, 1]\n",
      "Question `e8c3f59313df20db0cdd49b84a37c44da849fe17`: [2, 2, 2]\n",
      "Question `6cb3007a09ab0f1602cdad20cc0437fbdd4d7f3e`: [2, 2, 2]\n",
      "Question `87c00edc497274ae6a972c3097818de85b1b384f`: [1, 1, 5]\n",
      "Question `de4e949c6917ff6933f5fa2a3062ba703aba014c`: [1, 1, 3]\n",
      "Question `7380e62edcb11f728f6d617ee332dc8b5752b185`: [2, 1, 1]\n",
      "Question `ab37ae82e38f64d3fa95782f2c791488f26cd43f`: [0, 2, 0]\n",
      "Question `71413505d7d6579e2a453a1f09f4efd20197ab4b`: [0, 1, 2]\n",
      "Question `c2ce25878a17760c79031a426b6f38931cd854b2`: [2, 2, 1]\n",
      "Question `1d263356692ed8cdee2a13f103a82d98f43d66eb`: [2, 2, 1]\n",
      "Question `68f1df3fb0703ff694a055d23e7ec3f6fb449b8d`: [1, 2, 1]\n",
      "Question `c7f43c95db3d0c870407cd0e7becdd802463683b`: [2, 1, 1]\n",
      "Question `4e2b12cfc530a4682b06f8f5243bc9f64bd41135`: [2, 2, 0]\n",
      "Question `07edc082eb86aecef3db5cad2534459c1310d6e8`: [2, 2, 2]\n",
      "Question `3ea82a5ca495ffbd1e30e8655aef1be4ba423efe`: [2, 1, 1]\n",
      "Question `96356c1affc56178b3099ce4b4aece995032e0ff`: [0, 0, 2]\n",
      "Question `0f1f81b6d4aa0da38b4cc8b060926e7df61bb646`: [1, 2, 1]\n",
      "Question `ccec4f8deff651858f44553f8daa5a19e8ed8d3b`: [4, 2, 4]\n",
      "Question `649e77ac2ecce42ab2efa821882675b5a0c993cb`: [1, 10, 1, 1]\n",
      "Question `041529e15b70b21986adb781fd9b94b595e451ed`: [5, 1, 1]\n",
      "Question `1a0794ebbc9ee61bbb7ef2422d576a10576d9d96`: [2, 1, 0]\n",
      "Question `f85520bbc594918968d7d9f33d11639055458344`: [6, 5, 1]\n",
      "Question `f7b91b99279833f9f489635eb8f77c6d13136098`: [2, 1, 1]\n",
      "Question `99e514acc0109b7efa4e3860ce1e8c455f5bb790`: [2, 1, 1]\n",
      "Question `ac87dd34d28c3edd9419fa0145f3d38c87d696aa`: [1, 1, 2]\n",
      "Question `50bcbb730aa74637503c227f022a10f57d43f1f7`: [1, 1, 1, 2]\n",
      "Question `119c404da6e42d4879eee10edeab4b2851162659`: [2, 2, 1]\n",
      "Question `5c17559749810c67c50a7dbe34580d5e3b4f9acb`: [2, 1, 1]\n",
      "Question `475e698a801be0ad9e4f74756d1fff4fe0728009`: [1, 1, 2]\n",
      "Question `8246d1eee1482555d075127ac84f2e1d0781a446`: [1, 2, 1]\n",
      "Question `1ec0be667a6594eb2e07c50258b120e693e040a8`: [1, 2, 2]\n",
      "Question `1e11e74481ead4b7635922bbe0de041dc2dde28d`: [2, 2, 2]\n",
      "Question `f0404673085517eea708c5e91f32fb0f7728fa08`: [2, 1, 2]\n",
      "Question `48ff9645a506aa2c17810d2654d1f0f0d9e609ee`: [1, 2, 1]\n",
      "Question `1ff0ffeb2d0b2e150abdb2f559d8b31f4dd8aa2c`: [0, 2, 1]\n",
      "Question `8701ec7345ccc2c35eca4e132a8e16d58585cd63`: [1, 1, 2]\n",
      "Question `1a1d94c981c58e2f2ee18bdfc4abc69fd8f15e14`: [3, 5, 0]\n",
      "Question `5d790459b05c5a3e6f1e698824444e55fc11890c`: [3, 0, 0]\n",
      "Question `fb9e333a4e5d5141fe8e97b24b8f7e5685afbf09`: [2, 1, 1]\n",
      "Question `af45ff2c4209f14235482329d0729864fb2bd4b0`: [1, 2, 2]\n",
      "Question `c176eb1ccaa0e50fb7512153f0716e60bf74aa53`: [2, 2, 1]\n",
      "Question `1f8044487af39244d723582b8a68f94750eed2cc`: [2, 1, 1]\n",
      "Question `595fe416a100bc7247444f25b11baca6e08d9291`: [2, 1, 1]\n",
      "Question `1237b6fcc64b43901415f3ded17cc210a54ab698`: [2, 1, 2]\n",
      "Question `3a25f82512d56d9e1ffba72f977f515ae3ba3cca`: [1, 1, 2]\n",
      "Question `b59f3a58939f7ac007d3263a459c56ebefc4b49a`: [3, 4]\n",
      "Question `4748a50c96acb1aa03f7efd1b43376c193b2450a`: [2, 1, 2]\n",
      "Question `267d70d9f3339c56831ea150d2213643fbc5129b`: [4, 0, 1]\n",
      "Question `477da8d997ff87400c6aad19dcc74f8998bc89c3`: [1, 1, 2]\n",
      "Question `b9a3836cff16af7454c7a8b0e5ff90206d0db1f5`: [2, 0]\n",
      "Question `8c46a26f9b0b41c656b5b55142d491600663defa`: [1, 1, 2]\n",
      "Question `e5f8d2fc1332e982a54ee4b4c1f7f55e900d0b86`: [2, 1, 1]\n",
      "Question `2929e92f9b4939297b4d0f799d464d46e8d52063`: [1, 2, 2]\n",
      "Question `101d7a355e8bf6d1860917876ee0b9971eae7a2f`: [0, 2, 0]\n",
      "Question `4288621e960ffbfce59ef1c740d30baac1588b9b`: [1, 4, 1]\n",
      "Question `c3befe7006ca81ce64397df654c31c11482dafbe`: [1, 2]\n",
      "Question `3a01dc85ac983002fd631f1c28fc1cbe16094c24`: [1, 0, 2]\n",
      "Question `042800c3336ed5f4826203616a39747c61382ba6`: [1, 2, 1]\n",
      "Question `74fcb741d29892918903702dbb145fef372d1de3`: [3, 4]\n",
      "Question `6a20a3220c4edad758b912e2d3e5b99b0b295d96`: [2, 1, 3]\n",
      "Question `f92c344e9b1a986754277fd0f08a47dc3e5f9feb`: [1, 1, 3]\n",
      "Question `833d3ae7613500f2867ed8b33d233d71781014e7`: [5, 1, 1]\n",
      "Question `a1a0365bf6968cbdfd1072cf3923c26250bc955c`: [2, 2, 0]\n",
      "Question `8fdb4f521d3ba4179f8ccc4c28ba399aab6c3550`: [1, 2]\n",
      "Question `89414ef7fcb2709c47827f30a556f543b9a9e6e0`: [1, 2, 1]\n",
      "Question `faffcc6ef27c1441e6528f924e320368430d8da3`: [2, 1, 1]\n",
      "Question `e8fa4303b36a47a5c87f862458442941bbdff7d9`: [4, 1, 1]\n",
      "Question `58a3cfbbf209174fcffe44ce99840c758b448364`: [2, 3, 1]\n",
      "Question `6c6e06f7bfb6d30003fd3801fdaf34649ef1b8f4`: [2, 1, 2]\n",
      "Question `b6e97d1b1565732b1b3f1d74e6d2800dd21be37a`: [3, 2]\n",
      "Question `636ac549cf4917c5922cd09a655abf278924c930`: [1, 6]\n",
      "Question `de0154affd86c608c457bf83d888bbd1f879df93`: [3, 1]\n",
      "Question `9887ca3d25e2109f41d1da80eeea05c465053fbc`: [2, 1, 1]\n",
      "Question `78c7318b2218b906a67d8854f3e511034075f79a`: [1, 1, 2]\n",
      "Question `b948bb86855b2c0bfc8fad88ff1e29cd94bb6ada`: [1, 1, 2]\n",
      "Question `35c01dc0b50b73ee5ca7491d7d373f6e853933d2`: [0, 2]\n",
      "Question `2df3cd12937591481e85cf78c96a24190ad69e50`: [8, 8]\n",
      "Question `fc9aa04de4018b7d55e19a39663a2e9837328de7`: [1, 4]\n",
      "Question `8c89f1d1b3c2a45c0254c4c8d6e700ab9a4b4ffb`: [2, 1, 1]\n",
      "Question `f5bc07df5c61dcb589a848bd36f4ce9c22abd46a`: [1, 2]\n",
      "Question `8126c6b8a0cab3e22661d3d71d96aa57360da65c`: [1, 0, 2]\n",
      "Question `1a419468d255d40ae82ed7777618072a48f0091b`: [2, 1, 2]\n",
      "Question `8b1af67e3905244653b4cf66ba0acec8d6bff81f`: [1, 1, 2]\n",
      "Question `4ed58d828cd6bb9beca1471a9fa9f5e77488b1d1`: [3, 1]\n",
      "Question `ae89eed483c11ccd70a34795e9fe416af8a35da2`: [2, 1]\n",
      "Question `fc62549a8f0922c09996a119b2b6a8b5e829e989`: [2, 1, 1]\n",
      "Question `a3a867f7b3557c168d05c517c468ff6c7337bff9`: [2, 2]\n",
      "Question `1c8958ec50976a9b1088c51e8f73a767fb3973fa`: [2, 1, 1]\n",
      "Question `9186b2c5b7000ab7f15a46a47da73ea45544bace`: [1, 4, 1, 1]\n",
      "Question `d30b2fb5b29faf05cf5e04d0c587a7310a908d8c`: [1, 2]\n",
      "Question `2d91554c3f320a4bcfeb00aa466309074a206712`: [2, 1, 2]\n",
      "Question `252599e53f52b3375b26d4e8e8b66322a42d2563`: [2, 1]\n",
      "Question `275b2c22b6a733d2840324d61b5b101f2bbc5653`: [2, 1]\n",
      "Question `f1f7a040545c9501215d3391e267c7874f9a6004`: [2, 1, 1]\n",
      "Question `2ca3ca39d59f448e30be6798514709be7e3c62d8`: [1, 2]\n",
      "Question `20e2b517fddb0350f5099c39b16c2ca66186d09b`: [6, 0]\n",
      "Question `70512cc9dcd45157e40c8d1f85e82d21ade7645b`: [2, 1, 1]\n",
      "Question `058b6e3fdbb607fa7dbfc688628b3e13e130c35a`: [2, 1]\n",
      "Question `da077b385d619305033785af5b204696d6145bd8`: [2, 1, 3]\n",
      "Question `8ad5ebca2f69023b60ccfa3aac0ed426234437ac`: [2]\n",
      "Question `bdae851d4cf1d05506cf3e8359786031ac4f756f`: [2, 1]\n",
      "Question `894bbb1e42540894deb31c04cba0e6cfb10ea912`: [1, 2]\n",
      "Question `75b3e2d2caec56e5c8fbf6532070b98d70774b95`: [2, 1]\n",
      "Question `07d98dfa88944abd12acd45e98fb7d3719986aeb`: [8, 1]\n",
      "Question `3a40559e5a3c2a87c7b9031c89e762b828249c05`: [1, 2]\n",
      "Question `5db47bbb97282983e10414240db78154ea7ac75f`: [1, 2]\n",
      "Question `c589d83565f528b87e355b9280c1e7143a42401d`: [2, 1]\n",
      "Question `7f90e9390ad58b22b362a57330fff1c7c2da7985`: [2, 1]\n",
      "Question `3e3e45094f952704f1f679701470c3dbd845999e`: [3, 3]\n",
      "Question `3fd8eab282569b1c18b82f20d579b335ae70e79f`: [1, 2]\n",
      "Question `8e9561541f2e928eb239860c2455a254b5aceaeb`: [3, 0]\n",
      "Question `50c1bf8b928069f3ffc7f0cb00aa056a163ef336`: [2, 4]\n",
      "Question `2ddfb40a9e73f382a2eb641c8e22bbb80cef017b`: [3, 2]\n",
      "Question `860257956b83099cccf1359e5d960289d7d50265`: [2, 2]\n",
      "Question `d7e43a3db8616a106304ac04ba729c1fee78761d`: [0, 2]\n",
      "Question `70abb108c3170e81f8725ddc1a3f2357be5a4959`: [1, 2]\n",
      "Question `ce504a7ee2c1f068ef4dde8d435245b4e77bb0b5`: [1, 3]\n",
      "Question `d126d5d6b7cfaacd58494f1879547be9e91d1364`: [12, 10]\n",
      "Question `c3ce95658eea1e62193570955f105839de3d7e2d`: [1, 2]\n",
      "Question `ae7c5cf9c2c121097eb00d389cfd7cc2a5a7d577`: [1, 2]\n",
      "Question `b210c3e48c15cdc8c47cf6f4b6eb1c29a1933654`: [2, 1]\n",
      "Question `d0dc6729b689561370b6700b892c9de8871bb44d`: [2, 2]\n",
      "Question `17fd6deb9e10707f9d1b70165dedb045e1889aac`: [2, 1]\n",
      "Question `1faccdc78bbd99320c160ac386012720a0552119`: [1, 2]\n",
      "Question `5ae005917efc17a505ba1ba5e996c4266d6c74b6`: [1, 3]\n",
      "Question `72c04eb3fc323c720f7f8da75c70f09a35abf3e6`: [0, 4]\n",
      "Question `3138f916e253abed643d3399aa8a4555b2bd8c0f`: [1, 6]\n",
      "Question `ab8b0e6912a7ca22cf39afdac5531371cda66514`: [2, 1]\n",
      "Question `89373db8ced1fe420eae0093b2736f06b565616e`: [3, 1]\n",
      "Question `230f127e83ac62dd65fccf6b1a4960cf0f7316c7`: [1, 2]\n",
      "Question `75c221920bee14a6153bd5f4c1179591b2f48d59`: [1, 2]\n",
      "Question `cfc73e0c82cf1630b923681c450a541a964688b9`: [2, 0]\n",
      "Question `98b97d24f31e9c535997e9b6cb126eb99fc72a90`: [1, 2]\n",
      "Question `71b07d08fb6ac8732aa4060ae94ec7c0657bb1db`: [2, 1]\n",
      "Question `07104dd36a0e7fdd2c211ad710de9a605495b697`: [2, 3]\n",
      "Question `3e88fcc94d0f451e87b65658751834f6103b2030`: [2, 1]\n",
      "Question `998fa38634000f2d7b52d16518b9e18e898ce933`: [1, 2]\n",
      "Question `a82686c054b96f214521e468b17f0435e6cdf7cf`: [2, 1]\n",
      "Question `2ae66798333b905172e2c0954e9808662ab7f221`: [2, 0]\n",
      "Question `bd817a520a62ddd77e65e74e5a7e9006cdfb19b3`: [1, 2]\n",
      "Question `2e37eb2a2a9ad80391e57acb53616eab048ab640`: [2, 2]\n",
      "Question `7caeb5ef6f2985b2cf383cd01765d247c936605f`: [3, 1]\n",
      "Question `15aeda407ae3912419fd89211cdb98989d9cde58`: [1, 2]\n",
      "Question `a222dc5d804a7b453a0f7fbc1d6c1b165a3ccdd6`: [0, 3]\n",
      "Question `1128a600a813116cba9a2cf99d8568ae340f327a`: [2, 2]\n",
      "Question `d64fa192a7e9918c6a22d819abad581af0644c7d`: [3, 1]\n",
      "Question `3d1ad8a4aaa2653d0095bafba74738bd20795acf`: [5, 4]\n",
      "Question `344238de7208902f7b3a46819cc6d83cc37448a0`: [2, 1]\n",
      "Question `22225ba18a6efe74b1315cc08405011d5431498e`: [2, 2]\n",
      "Question `7239c02a0dcc0c3c9d9cddb5e895bcf9cfcefee6`: [2, 1]\n",
      "Question `1c2d4dc1e842b962c6407d6436f3dc73dd44ce55`: [4, 4]\n",
      "Question `654306d26ca1d9e77f4cdbeb92b3802aa9961da1`: [0, 3]\n",
      "Question `5a7d1ae6796e09299522ebda7bfcfad312d6d128`: [1, 3]\n",
      "Question `bd191d95806cee4cf80295e9ce1cd227aba100ab`: [3, 1]\n",
      "Question `50c441a9cc7345a0fa408d1ce2e13f194c1e82a8`: [1, 2]\n",
      "Question `ca595151735444b5b30a003ee7f3a7eb36917208`: [0, 3]\n",
      "Question `97abc2e7b39869f660986b91fc68be4ba196805c`: [1, 0, 2]\n",
      "Question `330fe3815f74037a9be93a4c16610c736a2a27b3`: [0, 2]\n",
      "Question `1f053f338df6d238cb163af1a0b1b073e749ed8a`: [2, 1]\n",
      "Question `361f330d3232681f1a13c6d59abb6c18246e7b35`: [1, 2]\n",
      "Question `f7d61648ae4bd46c603a271185c3adfac5fc5114`: [1, 2]\n",
      "Question `c9a323c152c5d9bc2d244e0ed10afbdb0f93062a`: [1, 2]\n",
      "Question `0dfe43985dea45d93ae2504cccca15ae1e207ccf`: [1, 2]\n",
      "Question `79885526713cc16eb734c88ff1169ae802cad589`: [2, 2]\n",
      "Question `b0e894536857cb249bd75188c3ca5a04e49ff0b6`: [0, 2]\n",
      "Question `94c22f72665dfac3e6e72e40f2ffbc8c99bf849c`: [3, 1]\n",
      "Question `ce8d8de78a21a3ba280b658ac898f73d0b52bf1b`: [1, 2]\n",
      "Question `2b32cf05c5e736f764ceecc08477e20ab9f2f5d7`: [2, 1]\n",
      "Question `14fdc8087f2a62baea9d50c4aa3a3f8310b38d17`: [3, 1]\n",
      "Question `f741d32b92630328df30f674af16fbbefcad3f93`: [1, 3]\n",
      "Question `fe7f7bcf37ca964b4dc9e9c7ebf35286e1ee042b`: [2, 0]\n",
      "Question `c035a011b737b0a10deeafc3abe6a282b389d48b`: [2, 2]\n",
      "Question `d323f0d65b57b30ae85fb9f24298927a3d1216e9`: [1, 2]\n",
      "Question `d576af4321fe71ced9e521df1f3fe1eb90d2df2d`: [3, 0]\n",
      "Question `89fa14a04008c93907fa13375f9e70b655d96209`: [2, 1]\n",
      "Question `3cc9a820c4a2cd2ff61da920c41ed09f3c0135be`: [1, 2]\n",
      "Question `e0b8a2649e384bbdb17472f8da2c3df4134b1e57`: [2, 3]\n",
      "Question `521a3e7300567f6e8e4c531f223dbc9fc306c393`: [2, 1]\n",
      "Question `4367617c0b8c9f33051016e8d4fbb44831c54d0f`: [2, 0]\n",
      "Question `2c60628d54f2492e0cbf0fb8bacd8e54117f0c18`: [1, 2]\n",
      "Question `77a331d4d909d92fab9552b429adde5379b2ae69`: [2, 1]\n",
      "Question `c53b036eff430a9d0449fb50b8d2dc9d2679d9fe`: [3, 2]\n",
      "Question `813a8156f9ed8ead53dda60ef54601f6ca8076e9`: [2, 1]\n",
      "Question `aa287673534fc05d8126c8e3486ca28821827034`: [3, 2]\n",
      "Question `8b8adb1d5a1824c8995b3eba668745c44f61c9c6`: [1, 2, 2]\n",
      "Question `415014a5bcd83df52c9307ad16fab1f03d80f705`: [2, 2]\n",
      "Question `7efbd9adbc403de4be6b1fb1999dd5bed9d6262c`: [2, 1]\n",
      "Question `95bbd91badbfe979899cca6655afc945ea8a6926`: [2, 2]\n",
      "Question `76ae794ced3b5ae565f361451813f2f3bc85b214`: [3, 1]\n",
      "Question `2bd702174e915d97884d1571539fb1b5b0b7123a`: [2, 1]\n",
      "Question `0c247a04f235a4375dd3b0fd0ce8d0ec72ef2256`: [1, 2]\n",
      "Question `0b5a7ccf09810ff5a86162d502697d16b3536249`: [2, 1]\n",
      "Question `e14e3e0944ec3290d1985e9a3da82a7df17575cd`: [1, 1, 2]\n",
      "Question `45e6532ac06a59cb6a90624513242b06d7391501`: [1, 2]\n",
      "Question `a98ae529b47362f917a398015c8525af3646abf0`: [1, 3]\n",
      "Question `a0197894ee94b01766fa2051f50f84e16b5c9370`: [2, 0]\n",
      "Question `55bafa0f7394163f4afd1d73340aac94c2d9f36c`: [2, 2]\n",
      "Question `cbb4eba59434d596749408be5b923efda7560890`: [2, 0]\n",
      "Question `90eeb1b27f84c83ffcc8a88bc914a947c01a0c8b`: [2, 1]\n",
      "Question `23cbf6ab365c1eb760b565d8ba51fb3f06257d62`: [3, 3]\n",
      "Question `f9ae1b31c1a60aacb9ef869e1cc6b0e70c6e5d8e`: [3, 3]\n",
      "Question `ed15a593d64a5ba58f63c021ae9fd8f50051a667`: [2, 1]\n",
      "Question `6c4e1a1ccc0c5c48115864a6928385c248f4d8ad`: [2, 1]\n",
      "Question `523bc4e3482e1c9a8e0cb92cfe51eea92c20e8fd`: [2, 1]\n",
      "Question `3d662fb442d5fc332194770aac835f401c2148d9`: [1, 2]\n",
      "Question `34b434825f0ca3225dc8914f9da865d2b4674f08`: [2, 2]\n",
      "Question `61a2599acfbd3d75de58e97ecdba2d9cf0978324`: [1, 2]\n",
      "Question `c27b885b1e38542244f52056abf288b2389b9fc6`: [4, 1]\n",
      "Question `65e26b15e087bedb6e8782d91596b35e7454b16b`: [2, 1]\n",
      "Question `a8f189fad8b72f8b2b4d2da4ed8475d31642d9e7`: [2, 1]\n",
      "Question `eafea4a24d103fdecf8f347c7d84daff6ef828a3`: [2, 1]\n",
      "Question `e099a37db801718ab341ac9a380a146c7452fd21`: [2, 1]\n",
      "Question `9da181ac8f2600eb19364c1b1e3cdeb569811a11`: [2, 1]\n",
      "Question `4999da863ecbd40378505bfb1f4e395061a3f559`: [2, 3]\n",
      "Question `3098793595252039f363ee1150d4ea956f2504b8`: [0, 2]\n",
      "Question `5f25b57a1765682331e90a46c592a4cea9e3a336`: [3, 2]\n",
      "Question `cfcf94b81589e7da215b4f743a3f8de92a6dda7a`: [2, 1]\n",
      "Question `d147117ef24217c43252d917d45dff6e66ff807c`: [2]\n",
      "Question `59a3d4cdd1c3797962bf8d72c226c847e06e1d44`: [3, 1]\n",
      "Question `30870a962cf88ac8c8e6b7b795936fd62214f507`: [2, 2]\n",
      "Question `7ece07a84635269bb19796497847e4517d1e3e61`: [1, 2]\n",
      "Question `f94cea545f745994800c1fb4654d64d1384f2c26`: [5, 2]\n",
      "Question `54b25223ab32bf8d9205eaa8a570e99c683f0077`: [2, 1]\n",
      "Question `9133a85730c4090fe8b8d08eb3d9146efe7d7037`: [2, 1]\n",
      "Question `42279c3a202a93cfb4aef49212ccaf401a3f8761`: [3, 2]\n"
     ]
    }
   ],
   "source": [
    "for qid, occurs in multisection_occurences.items():\n",
    "    print(f\"Question `{qid}`: {occurs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================  sbert - notitle ========================\n",
      "Total error cases that require answer from multiple sections: 138\n",
      "Percentage (compared to all multisection questions): 50.00%\n",
      "Percentage (compared to all questions): 9.51%\n",
      "\n",
      "=================  sbert - full ========================\n",
      "Total error cases that require answer from multiple sections: 134\n",
      "Percentage (compared to all multisection questions): 48.55%\n",
      "Percentage (compared to all questions): 9.24%\n"
     ]
    }
   ],
   "source": [
    "RETRIEVER = \"sbert\"\n",
    "READER = \"unified\"\n",
    "TOPK = 3\n",
    "modes = [\"notitle\", \"full\"]\n",
    "\n",
    "error_cases: Dict[str, Dict[str, Dict]] = {}\n",
    "for mode in modes:\n",
    "    error_case_path: Path = Path(f\"results/{RETRIEVER}-{READER}-{mode}-top{TOPK}/low_recall_cases.jsonl\")\n",
    "    with jsonlines.open(error_case_path) as reader:\n",
    "        multisection_errors: Dict[str, Dict] = {}\n",
    "        for question in reader:\n",
    "            question_id = question[\"qid\"]\n",
    "            if question_id in multisection_occurences.keys():\n",
    "                multisection_errors[question_id] = {\n",
    "                                                    \"question_text\": question[\"question\"],\n",
    "                                                    \"from_paper\": question[\"from_paper\"],\n",
    "                                                    \"from_paper\": question[\"from_paper\"],\n",
    "                                                    \"gold\": question[\"gold\"],\n",
    "                                                    \"gold_section\": question[\"gold_section\"],\n",
    "                                                    \"predicted\": question[\"predicted\"],\n",
    "                                                    \"predicted_section\": question[\"predicted_section\"],\n",
    "                                                    }\n",
    "        error_cases[mode] = multisection_errors\n",
    "\n",
    "    print(f\"\\n=================  {RETRIEVER} - {mode} ========================\")\n",
    "    print(f\"Total error cases that require answer from multiple sections: {len(multisection_errors)}\")\n",
    "    print(f\"Percentage (compared to all multisection questions): {len(multisection_errors)/len(multisection_occurences)*100:.2f}%\")\n",
    "    print(f\"Percentage (compared to all questions): {len(multisection_errors)/len(all_section_occurences)*100:.2f}%\")\n",
    "    \n",
    "# export error cases\n",
    "output_file: Path = Path(\"demo/multisection_error_cases.json\")\n",
    "with open(output_file, \"w+\") as f:\n",
    "    json.dump(error_cases, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa287673534fc05d8126c8e3486ca28821827034\n",
      "de4e949c6917ff6933f5fa2a3062ba703aba014c\n",
      "e8fa4303b36a47a5c87f862458442941bbdff7d9\n",
      "1ec0be667a6594eb2e07c50258b120e693e040a8\n",
      "8126c6b8a0cab3e22661d3d71d96aa57360da65c\n",
      "477da8d997ff87400c6aad19dcc74f8998bc89c3\n",
      "58a3cfbbf209174fcffe44ce99840c758b448364\n",
      "4367617c0b8c9f33051016e8d4fbb44831c54d0f\n",
      "8c89f1d1b3c2a45c0254c4c8d6e700ab9a4b4ffb\n",
      "f94cea545f745994800c1fb4654d64d1384f2c26\n",
      "230f127e83ac62dd65fccf6b1a4960cf0f7316c7\n",
      "330fe3815f74037a9be93a4c16610c736a2a27b3\n",
      "f8264609a44f059b74168995ffee150182a0c14f\n",
      "de0154affd86c608c457bf83d888bbd1f879df93\n",
      "1f8044487af39244d723582b8a68f94750eed2cc\n",
      "3fd8eab282569b1c18b82f20d579b335ae70e79f\n",
      "1a419468d255d40ae82ed7777618072a48f0091b\n",
      "47d54a6dd50cab8dab64bfa1f9a1947a8190080c\n",
      "91e361e85c6d3884694f3c747d61bfcef171bab0\n",
      "ab37ae82e38f64d3fa95782f2c791488f26cd43f\n",
      "bd817a520a62ddd77e65e74e5a7e9006cdfb19b3\n",
      "c58ef13abe5fa91a761362ca962d7290312c74e4\n",
      "14fdc8087f2a62baea9d50c4aa3a3f8310b38d17\n",
      "d0dc6729b689561370b6700b892c9de8871bb44d\n",
      "2ca3ca39d59f448e30be6798514709be7e3c62d8\n",
      "====================\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "notitle_qids: Set[str] = set(list(error_cases[\"notitle\"].keys()))\n",
    "full_qids: Set[str] = set(list(error_cases[\"full\"].keys()))\n",
    "\n",
    "# only_in_full: Set[str] = full_qids - notitle_qids\n",
    "# for qid in only_in_full:\n",
    "#     print(qid)\n",
    "# print(\"====================\")\n",
    "# only_in_notitle: Set[str] = notitle_qids - full_qids\n",
    "# for qid in only_in_notitle:\n",
    "#     print(qid)\n",
    "\n",
    "# fail in notitle , but not in fulltitle\n",
    "qids_better_in_full: List[str] = []\n",
    "\n",
    "for qid in notitle_qids:\n",
    "    if qid not in full_qids:\n",
    "        qids_better_in_full.append(qid)\n",
    "        print(qid)\n",
    "\n",
    "print(\"====================\")\n",
    "print(len(qids_better_in_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275b2c22b6a733d2840324d61b5b101f2bbc5653\n",
      "887d7f3edf37ccc6bf2e755dae418b04d2309686\n",
      "45e6532ac06a59cb6a90624513242b06d7391501\n",
      "7239c02a0dcc0c3c9d9cddb5e895bcf9cfcefee6\n",
      "2bd702174e915d97884d1571539fb1b5b0b7123a\n",
      "87c00edc497274ae6a972c3097818de85b1b384f\n",
      "9da181ac8f2600eb19364c1b1e3cdeb569811a11\n",
      "d38b3e0896b105d171e69ce34c689e4a7e934522\n",
      "a98ae529b47362f917a398015c8525af3646abf0\n",
      "78c7318b2218b906a67d8854f3e511034075f79a\n",
      "c176eb1ccaa0e50fb7512153f0716e60bf74aa53\n",
      "a8f189fad8b72f8b2b4d2da4ed8475d31642d9e7\n",
      "1f053f338df6d238cb163af1a0b1b073e749ed8a\n",
      "5ae005917efc17a505ba1ba5e996c4266d6c74b6\n",
      "b6e97d1b1565732b1b3f1d74e6d2800dd21be37a\n",
      "3d662fb442d5fc332194770aac835f401c2148d9\n",
      "7ece07a84635269bb19796497847e4517d1e3e61\n",
      "35c01dc0b50b73ee5ca7491d7d373f6e853933d2\n",
      "7380e62edcb11f728f6d617ee332dc8b5752b185\n",
      "1e11e74481ead4b7635922bbe0de041dc2dde28d\n",
      "5d03a82a70f7b1ab9829891403ec31607828cbd5\n",
      "====================\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# fail in fulltitle , but not in notitle\n",
    "\n",
    "qids_better_in_notitle: List[str] = []\n",
    "\n",
    "for qid in full_qids:\n",
    "    if qid not in notitle_qids:\n",
    "        qids_better_in_notitle.append(qid)\n",
    "        print(qid)\n",
    "\n",
    "print(\"====================\")\n",
    "print(len(qids_better_in_notitle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "qids_better_in_both: List[str] = list(set(qids_better_in_full).intersection(set(qids_better_in_notitle)))\n",
    "\n",
    "for qid in qids_better_in_both:\n",
    "    print(qid)\n",
    "\n",
    "print(\"====================\")\n",
    "print(len(qids_better_in_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4e2b12cfc530a4682b06f8f5243bc9f64bd41135\n",
      "a1a0365bf6968cbdfd1072cf3923c26250bc955c\n",
      "ecaa10a2d9927fa6ab6a954488f12aa6b42ddc1a\n",
      "ce8d8de78a21a3ba280b658ac898f73d0b52bf1b\n",
      "42279c3a202a93cfb4aef49212ccaf401a3f8761\n",
      "5f25b57a1765682331e90a46c592a4cea9e3a336\n",
      "54b25223ab32bf8d9205eaa8a570e99c683f0077\n",
      "042800c3336ed5f4826203616a39747c61382ba6\n",
      "344238de7208902f7b3a46819cc6d83cc37448a0\n",
      "c035a011b737b0a10deeafc3abe6a282b389d48b\n",
      "31e6062ba45d8956791e1b86bad7efcb6d1b191a\n",
      "3d1ad8a4aaa2653d0095bafba74738bd20795acf\n",
      "94c22f72665dfac3e6e72e40f2ffbc8c99bf849c\n",
      "07d98dfa88944abd12acd45e98fb7d3719986aeb\n",
      "3a25f82512d56d9e1ffba72f977f515ae3ba3cca\n",
      "1a1d94c981c58e2f2ee18bdfc4abc69fd8f15e14\n",
      "8b1af67e3905244653b4cf66ba0acec8d6bff81f\n",
      "252599e53f52b3375b26d4e8e8b66322a42d2563\n",
      "058b6e3fdbb607fa7dbfc688628b3e13e130c35a\n",
      "71413505d7d6579e2a453a1f09f4efd20197ab4b\n",
      "d147117ef24217c43252d917d45dff6e66ff807c\n",
      "8fdb4f521d3ba4179f8ccc4c28ba399aab6c3550\n",
      "72c04eb3fc323c720f7f8da75c70f09a35abf3e6\n",
      "595fe416a100bc7247444f25b11baca6e08d9291\n",
      "f5bc07df5c61dcb589a848bd36f4ce9c22abd46a\n",
      "ccec4f8deff651858f44553f8daa5a19e8ed8d3b\n",
      "5d790459b05c5a3e6f1e698824444e55fc11890c\n",
      "a3a867f7b3557c168d05c517c468ff6c7337bff9\n",
      "c0355afc7871bf2e12260592873ffdb5c0c4c919\n",
      "654306d26ca1d9e77f4cdbeb92b3802aa9961da1\n",
      "6e040e80f2da69d50386a90a38ed6d2fa4f77bbd\n",
      "34b434825f0ca3225dc8914f9da865d2b4674f08\n",
      "59a3d4cdd1c3797962bf8d72c226c847e06e1d44\n",
      "b59f3a58939f7ac007d3263a459c56ebefc4b49a\n",
      "101d7a355e8bf6d1860917876ee0b9971eae7a2f\n",
      "a57e266c936e438aeeab5e8d20d9edd1c15a32ee\n",
      "8e9561541f2e928eb239860c2455a254b5aceaeb\n",
      "a0197894ee94b01766fa2051f50f84e16b5c9370\n",
      "649e77ac2ecce42ab2efa821882675b5a0c993cb\n",
      "3e3e45094f952704f1f679701470c3dbd845999e\n",
      "415014a5bcd83df52c9307ad16fab1f03d80f705\n",
      "50c441a9cc7345a0fa408d1ce2e13f194c1e82a8\n",
      "95bbd91badbfe979899cca6655afc945ea8a6926\n",
      "780c7993d446cd63907bb38992a60bbac9cb42b1\n",
      "f7b91b99279833f9f489635eb8f77c6d13136098\n",
      "99e514acc0109b7efa4e3860ce1e8c455f5bb790\n",
      "636ac549cf4917c5922cd09a655abf278924c930\n",
      "f1f7a040545c9501215d3391e267c7874f9a6004\n",
      "ed15a593d64a5ba58f63c021ae9fd8f50051a667\n",
      "2b32cf05c5e736f764ceecc08477e20ab9f2f5d7\n",
      "b9a3836cff16af7454c7a8b0e5ff90206d0db1f5\n",
      "2df3cd12937591481e85cf78c96a24190ad69e50\n",
      "fe7f7bcf37ca964b4dc9e9c7ebf35286e1ee042b\n",
      "bdae851d4cf1d05506cf3e8359786031ac4f756f\n",
      "68f1df3fb0703ff694a055d23e7ec3f6fb449b8d\n",
      "7f90e9390ad58b22b362a57330fff1c7c2da7985\n",
      "6df57a21ca875e63fb39adece6a9ace5bb2b2cfa\n",
      "7efbd9adbc403de4be6b1fb1999dd5bed9d6262c\n",
      "20632fc4d2b693b5aabfbbc99ee5c1e9fc485dea\n",
      "90eeb1b27f84c83ffcc8a88bc914a947c01a0c8b\n",
      "5a7d1ae6796e09299522ebda7bfcfad312d6d128\n",
      "f85520bbc594918968d7d9f33d11639055458344\n",
      "30870a962cf88ac8c8e6b7b795936fd62214f507\n",
      "74fcb741d29892918903702dbb145fef372d1de3\n",
      "b0e894536857cb249bd75188c3ca5a04e49ff0b6\n",
      "d30b2fb5b29faf05cf5e04d0c587a7310a908d8c\n",
      "6c4e1a1ccc0c5c48115864a6928385c248f4d8ad\n",
      "f9ae1b31c1a60aacb9ef869e1cc6b0e70c6e5d8e\n",
      "860257956b83099cccf1359e5d960289d7d50265\n",
      "4288621e960ffbfce59ef1c740d30baac1588b9b\n",
      "a222dc5d804a7b453a0f7fbc1d6c1b165a3ccdd6\n",
      "74396ead9f88a9efc7626240ce128582ab69ef2b\n",
      "23cbf6ab365c1eb760b565d8ba51fb3f06257d62\n",
      "088d42ecb1e15515f6a97a0da2fed81b61d61a23\n",
      "d64fa192a7e9918c6a22d819abad581af0644c7d\n",
      "998fa38634000f2d7b52d16518b9e18e898ce933\n",
      "bc8526d4805e2554adb2e9c01736d3f3a3b19895\n",
      "61a2599acfbd3d75de58e97ecdba2d9cf0978324\n",
      "b584739622d0c53830e60430b13fd3ae6ff43669\n",
      "5ed02ae6c534cd49d405489990f0e4ba0330ff1b\n",
      "6cad6f074b0486210ffa4982c8d1632f5aa91d91\n",
      "cfc73e0c82cf1630b923681c450a541a964688b9\n",
      "d126d5d6b7cfaacd58494f1879547be9e91d1364\n",
      "e5f8d2fc1332e982a54ee4b4c1f7f55e900d0b86\n",
      "22225ba18a6efe74b1315cc08405011d5431498e\n",
      "e14e3e0944ec3290d1985e9a3da82a7df17575cd\n",
      "6295951fda0cfa2eb4259d544b00bc7dade7c01e\n",
      "cbb4eba59434d596749408be5b923efda7560890\n",
      "8246d1eee1482555d075127ac84f2e1d0781a446\n",
      "ab8b0e6912a7ca22cf39afdac5531371cda66514\n",
      "67cb001f8ca122ea859724804b41529fea5faeef\n",
      "9c1f70affc87024b4280f0876839309b8dddd579\n",
      "c27b885b1e38542244f52056abf288b2389b9fc6\n",
      "98b97d24f31e9c535997e9b6cb126eb99fc72a90\n",
      "523bc4e3482e1c9a8e0cb92cfe51eea92c20e8fd\n",
      "0dfe43985dea45d93ae2504cccca15ae1e207ccf\n",
      "371433bd3fb5042bacec4dfad3cfff66147c14f0\n",
      "1128a600a813116cba9a2cf99d8568ae340f327a\n",
      "c19e9fd2f1c969e023fb99b74e78eb1f3db8e162\n",
      "6a20a3220c4edad758b912e2d3e5b99b0b295d96\n",
      "c2ce25878a17760c79031a426b6f38931cd854b2\n",
      "75c221920bee14a6153bd5f4c1179591b2f48d59\n",
      "1c2d4dc1e842b962c6407d6436f3dc73dd44ce55\n",
      "cfdd583d01abaca923f5c466bb20e1d4b8c749ff\n",
      "50bcbb730aa74637503c227f022a10f57d43f1f7\n",
      "ac87dd34d28c3edd9419fa0145f3d38c87d696aa\n",
      "20e2b517fddb0350f5099c39b16c2ca66186d09b\n",
      "18fbfb1f88c5487f739aceffd23210a7d4057145\n",
      "b210c3e48c15cdc8c47cf6f4b6eb1c29a1933654\n",
      "eafea4a24d103fdecf8f347c7d84daff6ef828a3\n",
      "1ff0ffeb2d0b2e150abdb2f559d8b31f4dd8aa2c\n",
      "e099a37db801718ab341ac9a380a146c7452fd21\n",
      "ca595151735444b5b30a003ee7f3a7eb36917208\n",
      "====================\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "qids_fail_in_both: List[str] = list(notitle_qids.intersection(full_qids))\n",
    "\n",
    "for qid in qids_fail_in_both:\n",
    "    print(qid)\n",
    "\n",
    "print(\"====================\")\n",
    "print(len(qids_fail_in_both))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error case similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import jsonlines\n",
    "import torch\n",
    "import re\n",
    "# from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import utils\n",
    "\n",
    "os.environ['HF_HOME'] = '/workspace/P76125041/.cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"sentence-transformers/multi-qa-mpnet-base-cos-v1\", cache_folder=\"/workspace/P76125041/.cache/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTITLE CASE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"notitle\"\n",
    "TOPK = 10\n",
    "paper_id = \"2004.04124\"\n",
    "paper_para_embeddings: Dict[str, List[List[float]]] = utils.load_json(Path(f\"qasper/embeddings/test_embeddings_sbert_{MODE}.json\"))\n",
    "test_papers: Dict[str, Dict] = utils.load_json(Path(\"qasper/test_papers.json\"))\n",
    "raw_paras: List[str] = [para[\"text\"] for para in test_papers[paper_id].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does LadaBERT ever outperform its knowledge destilation teacher in terms of accuracy on some problems?\n",
      "Similarity scores of golden evidences:[0.4769901633262634, 0.5218134522438049]\n",
      "Similarity scores of predicted evidences:[0.6105265617370605, 0.5883709192276001, 0.5496411919593811]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Gold paragraph 1 found in top10! (score=0.5218133330345154), ranked 4\n",
      "Gold paragraph 0 found in top10! (score=0.476990282535553), ranked 6\n"
     ]
    }
   ],
   "source": [
    "# no title\n",
    "question = \"Does LadaBERT ever outperform its knowledge destilation teacher in terms of accuracy on some problems?\"\n",
    "\n",
    "# from section:\n",
    "    # Experiments ::: Performance Comparison\n",
    "    # Introduction\n",
    "    # Experiments ::: Learning curve comparison\n",
    "predicted = [\n",
    "    \"With model size of $2.5\\\\times $ reduction, LadaBERT-1 performs significantly better than BERT-PKD, boosting the performance by relative 8.9, 8.1, 6.1, 3.8 and 5.8 percentages on MNLI-m, MNLI-mm, SST-2, QQP and QNLI datasets respectively. Recall that BERT-PKD initializes the student model by selecting 3 of 12 layers in the pre-trained BERT-Base model. It turns out that the discarded layers have huge impact on the model performance, which is hard to be recovered by knowledge distillation. On the other hand, LadaBERT generates the student model by iterative pruning on the pre-trained teacher. In this way, the original knowledge in the teacher model can be preserved to the largest extent, and the benefit of which is complementary to knowledge distillation.\",\n",
    "    \"To further demonstrate the efficiency of LadaBERT, we visualize the learning curves on MNLI-m and QQP datasets in Figure FIGREF42 and FIGREF42, where LadaBERT-3 is compared to the strongest baseline, TinyBERT, under $7.5 \\\\times $ compression ratio. As shown in the figures, LadaBERT-3 achieves good performances much faster and results in a better convergence point. After training $2 \\\\times 10^4$ steps (batches) on MNLI-m dataset, the performance of LadaBERT-3 is already comparable to TinyBERT after convergence (approximately $2 \\\\times 10^5$ steps), achieving nearly $10 \\\\times $ acceleration. And on QQP dataset, both performance improvement and training speed acceleration is very significant. This clearly shows the superiority of combining matrix factorization, weight pruning and knowledge distillation in a reinforce manner. Instead, TinyBERT is based on pure knowledge distillation, so the learning speed is much slower.\",\n",
    "    \"We conduct extensive experiments on five public datasets of natural language understanding. As an example, the performance comparison of LadaBERT and state-of-the-art models on MNLI-m dataset is illustrated in Figure FIGREF1. We can see that LadaBERT outperforms other BERT-oriented model compression baselines at various model compression ratios. Especially, LadaBERT-1 outperforms BERT-PKD significantly under $2.5\\\\times $ compression ratio, and LadaBERT-3 outperforms TinyBERT under $7.5\\\\times $ compression ratio while the training speed is accelerated by an order of magnitude.\"\n",
    "    ]\n",
    "\n",
    "# from section: \n",
    "    #  Lightweight Adaptation of BERT ::: Overview\n",
    "    #  Experiments ::: Performance Comparison\n",
    "gold = [\n",
    "    \"The overall pipeline of LadaBERT (Lightweight Adaptation of BERT) is illustrated in Figure FIGREF8. As shown in the figure, the pre-trained BERT model (e.g., BERT-Base) is served as the teacher as well as the initial status of the student model. Then, the student model is compressed towards smaller parameter size through a hybrid model compression framework in an iterative manner until the target compression ratio is reached. Concretely, in each iteration, the parameter size of student model is first reduced by $1-\\\\Delta $ based on weight pruning and matrix factorization, and then the parameters are fine-tuned by the loss function of knowledge distillation. The motivation behind is that matrix factorization and weight pruning are complementary with each other. Matrix factorization calculates the optimal approximation under a certain rank, while weight pruning introduces additional sparsity to the decomposed matrices. Moreover, weight pruning and matrix factorization generates better initial and intermediate status of the student model, which improve the efficiency and effectiveness of knowledge distillation. In the following subsections, we will introduce the algorithms in detail.\",\n",
    "    \"The evaluation results of LadaBERT and state-of-the-art approaches are listed in Table TABREF40, where the models are ranked by parameter sizes for feasible comparison. As shown in the table, LadaBERT consistently outperforms the strongest baselines under similar model sizes. In addition, the performance of LadaBERT demonstrates the superiority of hybrid combination of SVD-based matrix factorization, weight pruning and knowledge distillation.\"\n",
    "]\n",
    "\n",
    "question_embedding: List[float] = embedding_model.encode([question])\n",
    "gold_embeddings: List[List[float]] = embedding_model.encode(gold)\n",
    "predicted_embeddings: List[List[float]] = embedding_model.encode(predicted)\n",
    "\n",
    "gold_similarity : List[float] = util.dot_score(question_embedding, gold_embeddings)[0].cpu().tolist()\n",
    "predicted_similarity : List[float] = util.dot_score(question_embedding, predicted_embeddings)[0].cpu().tolist()\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Similarity scores of golden evidences:{gold_similarity}\")\n",
    "print(f\"Similarity scores of predicted evidences:{predicted_similarity}\")\n",
    "\n",
    "print(\"+\"*100)\n",
    "all_stored_embeddings = paper_para_embeddings[paper_id]\n",
    "all_stored_similarity: List[float] = util.dot_score(question_embedding, all_stored_embeddings)[0].cpu().tolist()\n",
    "para_score_pairs = list(zip(raw_paras, all_stored_similarity))\n",
    "topk_para_score_pairs: List[Tuple[str, float]] = sorted(para_score_pairs, key=lambda x: x[1], reverse=True)[:TOPK]\n",
    "topk_paras: List[str] = [para for para, _ in topk_para_score_pairs]\n",
    "\n",
    "for rank, (para, score) in enumerate(topk_para_score_pairs, 1):\n",
    "    for gold_id, gold_para in enumerate(gold):\n",
    "        if gold_para in para:\n",
    "            print(f\"Gold paragraph {gold_id} found in top{TOPK}! (score={score}), ranked {rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FULL TITLE CASE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"full\"\n",
    "TOPK = 10\n",
    "paper_id = \"1805.11937\"\n",
    "paper_para_embeddings: Dict[str, List[List[float]]] = utils.load_json(Path(f\"qasper/embeddings/test_embeddings_sbert_{MODE}.json\"))\n",
    "test_papers: Dict[str, Dict] = utils.load_json(Path(\"qasper/test_papers.json\"))\n",
    "raw_paras: List[str] = [para[\"text\"] for para in test_papers[paper_id].values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What type of morphological features are used?\n",
      "Similarity scores of golden evidences:[0.4760808050632477, 0.41868165135383606]\n",
      "Similarity scores of predicted evidences:[0.46930956840515137, 0.4313605725765228, 0.4032084047794342]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Gold paragraph 0 found in top10! (score=0.4157830476760864), ranked 6\n",
      "Gold paragraph 1 found in top10! (score=0.3529841899871826), ranked 9\n"
     ]
    }
   ],
   "source": [
    "# full title\n",
    "\n",
    "question = \"What type of morphological features are used?\"\n",
    "\n",
    "# from section: \n",
    "    # Introduction\n",
    "    # Predicted Morphological Tags\n",
    "predicted = [\n",
    "    \"Morphological analysis already provides the aforementioned information about the words. However access to useful morphological features may be problematic due to software licensing issues, lack of robust morphological analyzers and high ambiguity among analyses. Character-level models (CLM), being a cheaper and accessible alternative to morphology, have been reported as performing competitively on various NLP tasks BIBREF0 , BIBREF1 , BIBREF2 . However the extent to which these tasks depend on morphology is small; and their relation to semantics is weak. Hence, little is known on their true ability to reveal the underlying morphological structure of a word and their semantic capabilities. Furthermore, their behaviour across languages from different families; and their limitations and strengths such as handling of long-range dependencies, reaction to model complexity or performance on out-of-domain data are unknown. Analyzing such issues is a key to fully understanding the character-level models.\",\n",
    "    \"We use a simple method based on bidirectional LSTMs to train three types of base semantic role labelers that employ (1) words (2) characters and character sequences and (3) gold morphological analysis. The gold morphology serves as the upper bound for us to compare and analyze the performances of character-level models on languages of varying morphological typologies. We carry out an exhaustive error analysis for each language type and analyze the strengths and limitations of character-level models compared to morphology. In regard to the diversity hypothesis which states that diversity of systems in ensembles lead to further improvement, we combine character and morphology-level models and measure the performance of the ensemble to better understand how similar they are.\",\n",
    "    \"Although models with access to gold morphological tags achieve better F1 scores than character models, they can be less useful a in real-life scenario since they require gold tags at test time. To predict the performance of morphology-level models in such a scenario, we train the same models with the same parameters with predicted morphological features. Predicted tags were only available for German, Spanish, Catalan and Czech. Our results given in Fig. 5 , show that (except for Czech), predicted morphological tags are not as useful as characters alone.\"\n",
    "]\n",
    "\n",
    "# from section: \n",
    "    # Subword Units\n",
    "gold = [\n",
    "    \"We use three types of units: (1) words (2) characters and character sequences and (3) outputs of morphological analysis. Words serve as a lower bound; while morphology is used as an upper bound for comparison. Table 1 shows sample outputs of various $\\\\rho $ functions.\",\n",
    "    \"Here, char function simply splits the token into its characters. Similar to n-gram language models, char3 slides a character window of width $n=3$ over the token. Finally, gold morphological features are used as outputs of morph-language. Throughout this paper, we use morph and oracle interchangably, i.e., morphology-level models (MLM) have access to gold tags unless otherwise is stated. For all languages, morph outputs the lemma of the token followed by language specific morphological tags. As an exception, it outputs additional information for some languages, such as parts-of-speech tags for Turkish. Word segmenters such as Morfessor and Byte Pair Encoding (BPE) are other commonly used subword units. Due to low scores obtained from our preliminary experiments and unsatisfactory results from previous studies BIBREF13 , we excluded these units.\"\n",
    "]\n",
    "\n",
    "question_embedding: List[float] = embedding_model.encode(question)\n",
    "gold_embeddings: List[List[float]] = embedding_model.encode(gold)\n",
    "predicted_embeddings: List[List[float]] = embedding_model.encode(predicted)\n",
    "\n",
    "\n",
    "gold_similarity : List[float] = util.dot_score(question_embedding, gold_embeddings)[0].cpu().tolist()\n",
    "predicted_similarity : List[float] = util.dot_score(question_embedding, predicted_embeddings)[0].cpu().tolist()\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Similarity scores of golden evidences:{gold_similarity}\")\n",
    "print(f\"Similarity scores of predicted evidences:{predicted_similarity}\")\n",
    "\n",
    "print(\"+\"*100)\n",
    "all_stored_embeddings = paper_para_embeddings[paper_id]\n",
    "all_stored_similarity: List[float] = util.dot_score(question_embedding, all_stored_embeddings)[0].cpu().tolist()\n",
    "para_score_pairs = list(zip(raw_paras, all_stored_similarity))\n",
    "topk_para_score_pairs: List[Tuple[str, float]] = sorted(para_score_pairs, key=lambda x: x[1], reverse=True)[:TOPK]\n",
    "topk_paras: List[str] = [para for para, _ in topk_para_score_pairs]\n",
    "\n",
    "for rank, (para, score) in enumerate(topk_para_score_pairs, 1):\n",
    "    for gold_id, gold_para in enumerate(gold):\n",
    "        if gold_para in para:\n",
    "            print(f\"Gold paragraph {gold_id} found in top{TOPK}! (score={score}), ranked {rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
